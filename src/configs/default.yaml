data:
  train_csv:
  tune_csv:
  test_csv:

output_dir: "output" # output directory

task: "classification" # task type: classification, regression, survival

num_classes: 2 # number of classes for classification task
label_name: "label"
label_mapping:

metrics: # list of metrics to compute
 - "auc"

features_dir: "/path/to/precomputed/slide/features"
features_dim: 1024

model:
  name: "mlp" # model name ("ab-mil", "hipt", "lp" or "mlp")
  level: "local" # hipt model level ("global" or "local")
  features_dim: ${features_dim}
  batch_size: 1
  hidden_dim: 256 # hidden dimension for "mlp" and "ab-mil" models
  num_layers: 3 # number of layers for "mlp" model
  gated: false # use gated attention mechanism in "ab-mil" model
  dropout: 0.0 # dropout rate, only for "hipt" and "ab-mil" models
  region_size: 2048 # region size for "hipt" model
  patch_size: 256 # patch size for "hipt" model
  embed_dim_patch: 384
  embed_dim_region: 192
  embed_dim_slide: 192
  pretrained_weights:
  img_size_pretrained:
  mask_attn: False
  num_register_tokens: 0

training:
  nepochs: 100
  batch_size: 1
  gradient_accumulation: 32

tuning:
  batch_size: 1
  tune_every: 1

testing:
  retrieve_checkpoint: "best"

optim:
  name: "adam"
  lr: 0.0002
  wd: 1e-5
  lr_scheduler:
    name: "step"
    step_size: 20
    gamma: 0.5

early_stopping:
  enable: false
  tracking: "loss"
  min_max: "min"
  patience: 10
  min_epoch: 30
  save_all: false

speed:
  num_workers: 8

wandb:
  enable: false
  project: "" # wandb project name
  username: "" # wandb username
  exp_name: "" # wandb experiment name
  tags: [] # wandb tags
  dir: "/home/user/"
  group: